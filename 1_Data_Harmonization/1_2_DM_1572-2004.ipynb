{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dutch Ministers (DM) 1572-2004\n",
    "\n",
    "The dataset **Dutch Ministers (DM)** is provided by the brothers van Lieburg and contains all the minister positions Dutch Reformed ministers had between 1572 and 2004. The dataset contains one row for ever carreer step of a minister and is said to **contain more up to date information** compared to [DRC](./1_1_DRC_1555-1816.ipynb). With every career step on a new row, this dataset contains multiple rows for every individual. For instance, Isaäc Abbema in the example below had two posts; one from 1618 to 1635 in Berkenwoude and from 1635 to 1637 in Gouda (figure 1).\n",
    "\n",
    "![Figure 2 Dutch Ministers 1572-2004](../images/figure2.png)\n",
    "\n",
    "*Figure 1 - Sample of Dutch Ministers 1572-2004 dataset* \n",
    "\n",
    "Contrary to [DRC](./1_1_DRC_1555-1816.ipynb), this dataset contains data about ministers that started their careers after 1816. What makes this dataset difficult to  work with is that individuals cannot be easily distinguished, since no unique ID is provide. Especially since over time people had the same names, individuals are not easily distinguishable. Out of the 53646 records this dataset contains, 25082 times exactly the same name is used. However, when only looking at the records that had the same name, unfeasible career paths occured. For instance the name \"J. de Jong\" would have had 30 positions over an unfeasible long period of time. Looking closely at “J. de Jong” it appears that this name represents multiple individuals (which is not a surprose in the Netherlands).\n",
    "\n",
    "![Figure 3](../images/figure3.png)\n",
    "\n",
    "*Figure 2 - Number of time a name appeared in DM* \n",
    "\n",
    "\n",
    "To integrate this dataset into the CLERUS dataset a pipeline to extract individuals out of this dataset is developed and presented in this notebook. The main idea for isolating individuals from DM is that carreer paths can be extracted by linking the rows based on the combination of the name, place where they were minister and the year that they started. This is possible since every row contains a value for the years they started and the year they left. In addition, the data contains the placename where they were minister and from where they came. Below in table 1 and example of the dataset is provided.\n",
    "\n",
    "\n",
    "|...|gemeente (community/ parish) |predikant (name of minster)| ... | jaar intrede (start year) |... | jaar vertrek (end year)| ... | ... |  \n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "|...|Hedikhuizen|Rosiere (Rosarius); Josephus van de |...| 1611 | ... | 1617 | ...| ...|\n",
    "|...|Woerden|Rosiere (Rosarius); Josephus van de | ... | 1617 | ... | 1619| ...| ...|\n",
    "|...|Haarlem|Rosiere (Rosarius); Josephus van de | ... | 1619 | ... | 1649| ...| ...|\n",
    "\n",
    "\n",
    "Table 1 shows the records related to one carreer. This minister, i.e. Josephus van de Rosiere (Rosarius), started his carreer as minister in 1611 in Hedikhuizen after which he moved to Woerden in 1617 where he got a position until 1619. In 1619 he moved to Haarlem where he stayed until 1649 when he retired or past away. To link the various records with each other a combination between name the start year and name and end year has been created after which, by applying network creation tooling, carreer paths can be constructed by linking start_node and end_node with each other. Since the data contained some inconsistancies in the use of spaces we decided to remove all spaces from the column \"predikant\" which contains the name of the minister.\n",
    "\n",
    "\n",
    "|...|gemeente (community/ parish) |predikant (name of minster)| ... | jaar intrede (start year) |... | jaar vertrek (end year)| ... | ... | pred_year_start | pred_year_end |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|...|Hedikhuizen|Rosiere (Rosarius); Josephus van de |...| 1611 | ... | 1617 | ...| ...|Rosiere(Rosarius);Josephusvande_1611| Rosiere(Rosarius);Josephusvande_1617|\n",
    "|...|Woerden|Rosiere (Rosarius); Josephus van de | ... | 1617 | ... | 1619| ...| ...|Rosiere(Rosarius);Josephusvande_1617 | Rosiere(Rosarius);Josephusvande_1619|\n",
    "|...|Haarlem|Rosiere (Rosarius); Josephus van de | ... | 1619 | ... | 1649| ...| ...|Rosiere(Rosarius);Josephusvande_1619 | Rosiere(Rosarius);Josephusvande_1649|\n",
    "\n",
    "\n",
    "### Manual cleaning\n",
    "\n",
    "Before performing this processing step, the DM dataset was cleaned. A thorough analysis scan of the dataset revealed a series of errors listed below. \n",
    "-\tInformation is stored in wrong column. \n",
    "-\tSpaces in front of name (make it difficult to link)\n",
    "-\t; between name and surname is lacking, making it at a later stage difficult to split these\n",
    "-\tMany individuals have only one value in the field predikant, making it difficult to link these thus it is difficult to distinguish surname or name \n",
    "\n",
    "A round of corrections has been executed and produced an updated list. Furthermore, it contains 131 records that still needs to be checked. This however does not mean that the rest of the file does not contain any errors. This data cleaning only looked at the following issues:\n",
    "-\twhether “jaar intrede” has a numeric value\n",
    "-\t“predikant” does not start with a number\n",
    "-\thow many semicolons there are in field “predikant” (and if not 1 put in the list to check)\n",
    "-\twhether “predikant” starts with a space\n",
    "\n",
    "Finally, every row has been given a unique ID number in the field \"pid\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for the project (i.e. the input location of the file to be processed and the output location etc.)\n",
    "\n",
    "folderlink = '..//data//'\n",
    "input_folder = 'input//'\n",
    "input_pred = folderlink+input_folder+\"DM_predikanten.csv\"\n",
    "output_folder = 'output//'\n",
    "output_pred = folderlink+output_folder+\"12_roles_dm.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panda settings for showing data\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that the year numbers are imported as integers\n",
    "jaar_vertrek_type = {'jaar vertrek': pd.Int64Dtype(), 'ind_id': pd.Int64Dtype(),'dag intrede': pd.Int64Dtype(), 'dag vertrek': pd.Int64Dtype() }\n",
    "df = pd.read_csv(input_pred, sep=',', dtype= jaar_vertrek_type, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is split in two. Since the dataset is composed of rows that have information about where someone went to ('vertrek naar of vanwege') and where he or she came from ('Herkomst'), which is foremost for ministers from after 1816, and rows that have only a year when they move position a cut was made based on the field Herkomst having values NaN.\n",
    "# The former is named dm_part2, the latter dm_part1.\n",
    "\n",
    "dm_part1 = df[df['Herkomst'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here all the spaces from predikant are removed\n",
    "dm_part1['predikant'] = df['predikant'].str.replace(' ', '')\n",
    "# Next the fields are created which are used as input for identifying carreer paths in the dataset\n",
    "dm_part1['pred_year_start'] = dm_part1['predikant'].astype(str)+'_'+dm_part1['jaar intrede'].astype(str)\n",
    "dm_part1['pred_year_end'] = dm_part1['predikant'].astype(str)+'_'+dm_part1['jaar vertrek'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next the variables are set for the input of the network tool graph tool used.\n",
    "tdf = dm_part1\n",
    "variable_end = 'pred_year_end'\n",
    "variable_start = 'pred_year_start'\n",
    "variable_name = 'predikant'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function is created for the graph G tool.\n",
    "\n",
    "def create_node_paths_dataframe(dataframe):\n",
    "    # Generate the directed graph G\n",
    "    G = nx.DiGraph()\n",
    "    for _, row in dataframe.iterrows():\n",
    "        G.add_edge(row[variable_start], row[variable_end], name=row[variable_name])\n",
    "\n",
    "    # Find connected components and assign path ides\n",
    "    paths = list(nx.connected_components(G.to_undirected()))\n",
    "    path_ids = list(range(1, len(paths) + 1))\n",
    "    node_path_pairs = []\n",
    "    for path_id, path_nodes in zip(path_ids, paths):\n",
    "        node_path_pairs.extend([(node, path_id) for node in path_nodes])\n",
    "\n",
    "    # Next we create a DataFrame from the node-path pairs and add the a new field to the connecting paths allowing to assign individuals in the dataset.\n",
    "    node_paths = pd.DataFrame(node_path_pairs, columns=[variable_start, 'individual_id'])\n",
    "\n",
    "    # next we need to join the original DataFrame with the node-paths DataFrame to add the individual_id which distinguished individuals\n",
    "    joined = pd.merge(dataframe, node_paths, left_on=variable_start, right_on=variable_start, how='left')\n",
    "\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the created function\n",
    "result_dm_part1 = create_node_paths_dataframe(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the dataset with a selection of the fields\n",
    "individuals_p1 = result_dm_part1[['pid',variable_name,'individual_id']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are doing the same for the second part of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_part2 = df[df['Herkomst'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_part2['gemeente'] = dm_part2['gemeente'].str.replace(' ', '')\n",
    "dm_part2['vertrek naar of vanwege'] = dm_part2['vertrek naar of vanwege'].str.replace(' ', '')\n",
    "\n",
    "dm_part2['gemeente'] = dm_part2['gemeente'].str[:6]\n",
    "dm_part2['vertrek naar of vanwege'] = dm_part2['vertrek naar of vanwege'].str[:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_part2['predikant'] = dm_part2['predikant'].str.replace(' ', '')\n",
    "dm_part2['pred_start'] = dm_part2['predikant'].astype(str)+'_'+dm_part2['gemeente'].astype(str)+'_'+dm_part2['jaar intrede'].astype(str)\n",
    "dm_part2['pred_end'] = dm_part2['predikant'].astype(str)+'_'+dm_part2['vertrek naar of vanwege'].astype(str)+'_'+dm_part2['jaar vertrek'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_part2 = dm_part2.sort_values(by='pred_start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = dm_part2\n",
    "variable_end = 'pred_end'\n",
    "variable_start = 'pred_start'\n",
    "variable_name = 'predikant'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dm_part2 = create_node_paths_dataframe(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals_p2 = result_dm_part2[['pid',variable_name,'individual_id']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine the two outputs into one list. To avoid overlap between the created id fields we add the max value for the individuals in part 1 to the ids of the second part of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_part1_max = individuals_p1['individual_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals_p2['individual_id']= individuals_p2['individual_id'] + dm_part1_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals = pd.concat([individuals_p1, individuals_p2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an export of the ministers to be linked with CLERUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals = individuals.drop('predikant', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, individuals, left_on='pid', right_on='pid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_pred, sep=',', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
