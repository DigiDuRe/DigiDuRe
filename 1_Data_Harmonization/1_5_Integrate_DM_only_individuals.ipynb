{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "current_date = datetime.now()\n",
    "formatted_date = current_date.strftime('%d%m%Y')\n",
    "\n",
    "def copy_database(original_path, temp_path):\n",
    "    shutil.copyfile(original_path, temp_path)\n",
    "\n",
    "def export_access_to_dataframes(database_path):\n",
    "    # Connection string for Access database\n",
    "    conn_str = (\n",
    "        r'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};'\n",
    "        r'DBQ=' + database_path + ';'\n",
    "    )\n",
    "\n",
    "    # Establish a connection to the Access database\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get a list of all tables in the database\n",
    "    tables = [row.table_name for row in cursor.tables(tableType='TABLE')]\n",
    "\n",
    "    # Loop through the tables and load each into a DataFrame\n",
    "    for table in tables:\n",
    "        query = f'SELECT * FROM [{table}]'\n",
    "        df = pd.read_sql(query, conn)\n",
    "        globals()[f'tbl_{table}'] = df  # Create a global variable with the table name\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "def update_access_table(database_path, table_name, df):\n",
    "    # Connection string for Access database\n",
    "    conn_str = (\n",
    "        r'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};'\n",
    "        r'DBQ=' + database_path + ';'\n",
    "    )\n",
    "\n",
    "    # Establish a connection to the Access database\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Clear the existing table\n",
    "    cursor.execute(f'DELETE FROM [{table_name}]')\n",
    "    conn.commit()\n",
    "\n",
    "    # Insert the updated data\n",
    "    for index, row in df.iterrows():\n",
    "        columns = ', '.join(row.index)\n",
    "        placeholders = ', '.join(['?' for _ in row])\n",
    "        values = tuple(row)\n",
    "        sql = f'INSERT INTO [{table_name}] ({columns}) VALUES ({placeholders})'\n",
    "        cursor.execute(sql, values)\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "# Paths\n",
    "original_database_path = 'E:\\\\digidure\\\\CLERUS_v1_DRC_07082024.accdb'\n",
    "temp_database_path = 'E:\\\\digidure\\\\CLERUS_v2_DRC_DM_'+formatted_date+'.accdb'\n",
    "\n",
    "# Copy the database\n",
    "copy_database(original_database_path, temp_database_path)\n",
    "\n",
    "# Export data from the copied database\n",
    "export_access_to_dataframes(temp_database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to append the data to access database\n",
    "def append_to_access_table(df, database_path, table_name):\n",
    "    \"\"\"\n",
    "    Appends a DataFrame to a table in an Access database.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame to append.\n",
    "    database_path (str): The path to the Access database file.\n",
    "    table_name (str): The name of the table to append the data to.\n",
    "    \"\"\"\n",
    "    # Connection string for Access database\n",
    "    connection_string = (\n",
    "        r'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};'\n",
    "        r'DBQ=' + database_path + ';'\n",
    "    )\n",
    "\n",
    "    # Connect to the Access database\n",
    "    conn = pyodbc.connect(connection_string)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Append DataFrame to the Access table\n",
    "    for index, row in df.iterrows():\n",
    "        columns = ', '.join(row.index)\n",
    "        values = ', '.join(['?' for _ in row])\n",
    "        sql = f'INSERT INTO {table_name} ({columns}) VALUES ({values})'\n",
    "        cursor.execute(sql, tuple(row))\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panda settings for showing data (this is foremost done to more easily explore the data while processing it)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the individuals that could be matched with DRC are already curated and processed. The next step is to extract individuals from DM that are not in DRC.\n",
    "# When a link between DM and DRC was found, a value for clerus_id or new_clerus_id was produced. Thus to isolate those that have not been matched we create\n",
    "# a subselection existing of rows where these fields are empty.\n",
    "filtered_only_DM = tbl_999_Dm_all_drc_match[tbl_999_Dm_all_drc_match['clerus_id'].isna() & tbl_999_Dm_all_drc_match['new_clerus_id'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we want to link the individuals to clerus we want to use the individual_id lateron as a new clerus_id. To avoid overlap in numbers we added 9000000 to every id. The individual ids have been created through 2_1_check_links_DRC_DM.ipynb\n",
    "filtered_only_DM[\"individual_id\"] = filtered_only_DM[\"individual_id\"] + 9000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this dataset we will be extracting all kind of information to align with the Clerus database structure.\n",
    "# First we extract information for every individual which we use to fill in the table 01_clerus_bio. These are the names of the individual, the year of death and remarks (Bijzonderheden).\n",
    "# since we are not interested in all the other fields we make a subselection\n",
    "\n",
    "DM_tbl_bio_1 = filtered_only_DM[['pid', 'predikant', \"vertrek naar of vanwege\", \"jaar vertrek\", \"Bijzonderheden\", \"individual_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Year of Death\n",
    "# After analysing the data in DM it appears that information about someone's year of death can be found in the field \"Bijzonderheden\", but also in the field \"vertrek naar of vanwege\".\n",
    "# To extract this information and to save it in a new field is done in two steps.\n",
    "\n",
    "# first we extract year from Bijzonderheden where it contains the string \"overl.\" or \"overleden\"\n",
    "def extract_year(bijzonderheden):\n",
    "    if isinstance(bijzonderheden, str):\n",
    "        match = re.search(r'(overleden|overl\\.)\\s*(\\d{4})', bijzonderheden, re.IGNORECASE)\n",
    "        if match:\n",
    "            return int(match.group(2))\n",
    "    return None\n",
    "\n",
    "DM_tbl_bio_1['death_year'] = DM_tbl_bio_1['Bijzonderheden'].apply(extract_year)\n",
    "\n",
    "# Second we update 'death_year' where it is None, using 'jaar_vertrek' if 'vertrek_naar_of_vanwege' contains 'overleden' or 'overl.'\n",
    "DM_tbl_bio_1['death_year'] = DM_tbl_bio_1.apply(\n",
    "    lambda row: row['jaar vertrek']\n",
    "    if pd.isnull(row['death_year']) and\n",
    "       isinstance(row['vertrek naar of vanwege'], str) and\n",
    "       ('overleden' in row['vertrek naar of vanwege'].lower() or 'overl.' in row['vertrek naar of vanwege'].lower())\n",
    "    else row['death_year'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we need to make another subselection of the data to get only the name, clerus_id, year of death and remarks.\n",
    "DM_tbl_bio_2 = DM_tbl_bio_1[['predikant', \"Bijzonderheden\", \"individual_id\", \"death_year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_tbl_bio_2['death_year'] = DM_tbl_bio_2['death_year'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we remove all duplicates that remain based on the inidivual_id and prioritize on whether \"year_death\" has a value.\n",
    "DM_tbl_bio_2 = DM_tbl_bio_2.sort_values(by='death_year', ascending=False, na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on 'individual_id', keeping the first occurrence\n",
    "DM_tbl_bio_unique = DM_tbl_bio_2.drop_duplicates(subset='individual_id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_tbl_bio_unique[['surname', 'first_name']] = DM_tbl_bio_unique['predikant'].str.split(';', expand=True)\n",
    "DM_tbl_bio_unique.drop(columns=['predikant'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_tbl_bio_unique.rename(columns={'Bijzonderheden': 'remarks', 'individual_id': 'clerus_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_tbl_bio_unique['remarks_source'] = \"DM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add information about the sex to the individual in DM. All are male except when the name contains \"mevr\" or \"mevrouw\"\n",
    "\n",
    "def determine_sex(first_name):\n",
    "    if first_name and 'mevr' in first_name.lower():\n",
    "        return 'female'\n",
    "    else:\n",
    "        return 'male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_tbl_bio_unique['sex'] = DM_tbl_bio_unique['first_name'].apply(determine_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infixes = [ \" ter\",\" ten\", \" van der\", \" van den\", \" van\", \" den\", \" der\", \" de\",\n",
    "            \".ter\",\".ten\", \".van der\", \".van den\", \".van\", \".den\", \".der\", \".de\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_infix(name, infixes):\n",
    "    if name is None:\n",
    "        return None\n",
    "    for infix in infixes:\n",
    "        if infix in name:\n",
    "            return infix\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_tbl_bio_unique['infix'] = DM_tbl_bio_unique['first_name'].apply(lambda x: extract_infix(x, infixes))\n",
    "DM_tbl_bio_unique['infix'] = DM_tbl_bio_unique['infix'].str.replace('.', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_infix(name, infix):\n",
    "    if name and infix:\n",
    "        return name.replace(infix, '').strip()\n",
    "    return name\n",
    "\n",
    "DM_tbl_bio_unique['first_name'] = DM_tbl_bio_unique.apply(lambda row: remove_infix(row['first_name'], row['infix']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append data to database\n",
    "table_name = '01_clerus_bio'\n",
    "append_to_access_table(DM_tbl_bio_unique, temp_database_path, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_death = DM_tbl_bio_unique[['clerus_id','death_year']]\n",
    "bio_death.rename(columns={'death_year': 'temp_death_year_DM'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get roles seperate out of the dataframe where roles from individuals that are only present in DM are used. (i.e. filtered_only_DM)\n",
    "# Provincie [role_province], Classis [role_classis], Gemeente [role_place], clerus_id, pid(as backup), jaar intrede [year_start], jaar vertrek [year_end], dag intrede - maand intrede - jaar intrede [role_start_accuracy], dag vertrek - maand vertrek - jaar vertrek [role_end_accuracy]\n",
    "\n",
    "filtered_only_DM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "role_dm = filtered_only_DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the day, month and year create a date field which we will fill in to start_date_accuracy and end_date_accuracy\n",
    "role_dm['role_start_date_exact'] = role_dm['dag intrede'].astype(str) + \" \" + role_dm['maand intrede'] + \" \" + role_dm['jaar intrede'].astype(str)\n",
    "role_dm['role_end_date_exact'] = role_dm['dag vertrek'].astype(str) + \" \" + role_dm['maand vertrek'] + \" \" + role_dm['jaar vertrek'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_dm.drop(columns=['ind_id','clerus_id', 'new_clerus_id', 'dag vertrek', 'maand vertrek', 'dag intrede', 'maand intrede', 'vertrek naar of vanwege', 'Herkomst'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_dm.rename(columns={'Bijzonderheden': 'role_remarks',\n",
    "                        'individual_id': 'clerus_id',\n",
    "                        'pid':'role_source_id',\n",
    "                        'provincie': 'role_province',\n",
    "                        'classis': 'role_classis',\n",
    "                        'gemeente': 'role_place',\n",
    "                        'wijk': 'role_parish',\n",
    "                        'jaar intrede': 'role_start_year',\n",
    "                        'jaar vertrek': 'role_end_year',\n",
    "                        'predikant':'temp_name_surname'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_dm['role_type'] = \"predikant\"\n",
    "role_dm['role_remarks_source'] = \"DM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_dm['role_end_year'] = role_dm['role_end_year'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_dm = role_dm.replace({np.nan: ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_dm_death = pd.merge(role_dm, bio_death, on='clerus_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = '12_clerus_role'\n",
    "append_to_access_table(role_dm_death, temp_database_path, table_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
