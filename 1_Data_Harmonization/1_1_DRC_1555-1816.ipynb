{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b5865b5",
   "metadata": {},
   "source": [
    "# Database Dutch Reformed Clergy (DRC) 1555-1816\n",
    "\n",
    "The Database Dutch Reformed Clergy (DRC) 1555-1816 (stored as Repertoriummetoudepersoonsnummers1.docx) is provided by prof. dr. Fred van Lieburg of which an earlier version is published under [van Lieburg, F. A. (1997). Profeten en hun vaderland. De geografische herkomst van de gereformeerde predikanten in Nederlamd van 1572 tot 1816. [PhD-Thesis - Research and graduation internal, Vrije Universiteit Amsterdam]. Boekencentrum.](https://hdl.handle.net/1871.1/e1bfb2c9-8d30-42b4-8edf-83b20bd6c5a7) . This dataset contains biographical information and career path information of Dutch ministers that started after 1555 until the starting data 1816. This means that it does contain careers that continue after 1816, but no individuals that started after 1816. \n",
    "\n",
    "The dataset contains 12558 individuals which are systematically registered in a text file. A sample of the text is provided below.\n",
    "\n",
    "> Aalst; Wilhelmus Gedoopt Biggekerke 5 jan. 1664; pred. Aardenburg 22 mei 1695, overl. 19 dec. 1700.<4>\n",
    ">\n",
    "> Aalst, van; Cornelius Geb. Castricum ca. 1686; ambassadepred. in Parijs maart tot dec. 1715; pred. Kalslagen ber. 21 febr. 1717, emer. 1751; overl. Amsterdam 27 aug. 1756.<2>\n",
    ">\n",
    "> Aalst, van; Gerardus Geb. xxx sept. 1678; pred. Vuren en Dalem 10 aug. 1704, Sommelsdijk 13 juni 1706, West Zaandam 4 aug. 1715, emer. 1755; overl. 29 juni 1759.<3>\n",
    ">\n",
    "\n",
    "Having this dataset in this form does not allow to categorize persons based on the place that they were born or years that they were active in a certain church. In its current form the dataset thus does not allow to be analysed systematically. Valueable historical insight remain hidden. To open this dataset for systematic analyses, the first steps is to parse the dataset into a relation database. By doing so a series of basic and more advanced analysis methods will become present. Transforming the data in a Relational Database will allow it to be queried systematically. Furthermore, it allows for more complex analyses to see which individuals lived near to each other and eventually allowing it to be linked with other datasets such as book title datasets. \n",
    "\n",
    "The steps in this notebook provide the process on how the text file has been converted into a series of csv files which can be imported into a Relational Database. Since the dataset, at the end of the processing, still contained significant errors, the whole dataset did also underwent a manual curation round. The notebook presents that tailor made processing steps to parse the data. The overall principle for the steps that were taken is that the information of an individual is stored on a single line and that all characteristics are parsed into separate columns based on specific strings that seperate distinguishable items. Although the pipeline did structure most the data succesfully, still a manual curation was required to fully check the data. \n",
    "\n",
    "Note, that since it was a one time processing pipeline the notebook has not been optimized, yet it does contain extensive explanatory texts on the processing steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac6cbb8",
   "metadata": {},
   "source": [
    "### Step 0 import libraries and configure settings\n",
    "The required python libraries for the notebook are imported. In case you are new to python and installing libraries have a look [here](../4_Dissemination/install_packages.md) . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ed42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43138848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for the project (i.e. the input location of the file to be processed and the output location) )\n",
    "\n",
    "folderlink = '..//data//'\n",
    "input_folder = 'input//'\n",
    "input_file = os.path.join(folderlink+input_folder, 'Repertoriummetoudepersoonsnummers1.docx')\n",
    "folder_output = 'output//'\n",
    "output_txt = folderlink+folder_output+'output.txt'\n",
    "output_csv = folderlink+folder_output+'output_file.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e90265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panda settings for showing data (this is foremost done to more easily explore the data while processing it)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ecb448",
   "metadata": {},
   "source": [
    "### Step 1 Convert .docx file and parse individuals to seperate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e8c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the docx to a text file and remove all unecessary rows.\n",
    "\n",
    "# Use docx2txt library to extract text from .docx file\n",
    "text = docx2txt.process(input_file)\n",
    "\n",
    "# Remove excessive whitespaces\n",
    "data = ' '.join(text.split())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f16639df",
   "metadata": {},
   "source": [
    "While processing the data some clear errors occured resulting which were updated as follows:\n",
    "\n",
    "1.  FROM: \"N.N. \"de oude vicarius\">pred. Lichtenvoorde 1602 tot 1615.<20871>\"\n",
    "    TO: \"N.N. \"de oude vicarius\" pred. Lichtenvoorde 1602 tot 1615.<20871>\" \n",
    "    REASON: since it contained the > character which is used to define ID fields. \n",
    " \n",
    "2.  FROM: \"Bosch; Cornelius Geb. Utrecht 1634; pred. Renswoude 16 dec. 1656, Maasland 15 april 1663, Brielle 30 jan. 1667, Alkmaar 1667, 's Gravenhage 5 juli 1676, emer. 1713,;overl. 28 maart 1715.<1185>\"\n",
    "    TO:Bosch; Cornelius\n",
    "Geb. Utrecht 1634; pred. Renswoude 16 dec. 1656, Maasland 15 april 1663, Brielle 30 jan. 1667, Alkmaar 1667, 's Gravenhage 5 juli 1676, emer. 1713, overl. 28 maart 1715.<1185>\n",
    "    REASON: Since it splitted the string based on \",;overl\"\n",
    "\n",
    "3.  FROM: Leeuwen, van, Cornelis [z.v. Cornelis]\n",
    "Geb. Hazerswoude 1611; pred. Boskoop en Middelburg 1637, overl. 1681.<5778>\n",
    "    TO: Leeuwen, van; Cornelis [z.v. Cornelis]\n",
    "Geb. Hazerswoude 1611; pred. Boskoop en Middelburg 1637, overl. 1681.<5778>\n",
    "    REASON: there was no ; between the name and surname (including infix)\n",
    "\n",
    "4.  FROM: Peenen, van, Marcus\n",
    "Gedoopt Leiden 31 aug. 1642; pred. Koudekerk aan den Rijn 2 sept. 1668, Leiden 1680, begraven 1 febr. 1696.<7388>\n",
    "    TO: Peenen, van; Marcus\n",
    "Gedoopt Leiden 31 aug. 1642; pred. Koudekerk aan den Rijn 2 sept. 1668, Leiden 1680, begraven 1 febr. 1696.<7388>\n",
    "    REASON: there was no ; between the name and surname (including infix)\n",
    "\n",
    "5.  FROM: Knuyt, de (Kuntius), Elias\n",
    "Geb. Middelburg yyy; pred. Oude Niedorp en Veenhuizen (NH) mei 1628, Sint Annaland 1630, Westkapelle 7 maart 1641, overl. --of vertrokken?-- 1642.<5381>\n",
    "    TO: Knuyt, de (Kuntius); Elias\n",
    "Geb. Middelburg yyy; pred. Oude Niedorp en Veenhuizen (NH) mei 1628, Sint Annaland 1630, Westkapelle 7 maart 1641, overl. --of vertrokken?-- 1642.<5381>\n",
    "    REASON: there was no ; between the name and surname (including infix)\n",
    "\n",
    "6.  FROM: Leonardis, de, Paulus\n",
    "Geb. Keulen yyy; pred. Bacharach (Pfalz) 16.., Kampen 1620, overl. 1649.<5836>\n",
    "    TO: Leonardis, de; Paulus\n",
    "Geb. Keulen yyy; pred. Bacharach (Pfalz) 16.., Kampen 1620, overl. 1649.<5836>\n",
    "    REASON: there was no ; between the name and surname (including infix)\n",
    "\n",
    "7.  FROM: Tamerus; Henricus\n",
    "Geb. xxx ca. 1540; voorheen Lutheraan;--onwettig pred. Heteren en Randwijk ca. 1600-1602; pred. Eethen en Meeuwen 1606, Doeveren, Gansoyen en Genderen 1610, afgezet als remonstrant 1619; overl. Heusden.<21206>\n",
    "    TO: Tamerus; Henricus\n",
    "Geb. xxx ca. 1540; voorheen Lutheraan; onwettig pred. Heteren en Randwijk ca. 1600-1602; pred. Eethen en Meeuwen 1606, Doeveren, Gansoyen en Genderen 1610, afgezet als remonstrant 1619; overl. Heusden.<21206>\n",
    "    REASON: -- conflicted created a line break. \n",
    "    \n",
    "8. FROM Aitton; Rijk Otto [z.v. Hendrik Arnold]\n",
    "Geb. Zwolle 27 maart 1790; pred. Zuilichem + Nieuwaal 3 maart 1811, --legerpred. 1815, garnizoenspred. Oostende (Vlaanderen)-- Aalten 11 mei 1817, Hooge Zwaluwe 9 april 1826, Monster 4 mei 1828, Zevenbergen 5 april 1840, emer. 1855; overl. 4 aug. 1863.<130>\n",
    "    TO: Aitton; Rijk Otto [z.v. Hendrik Arnold]\n",
    "Geb. Zwolle 27 maart 1790; pred. Zuilichem + Nieuwaal 3 maart 1811, legerpred. 1815, garnizoenspred. Oostende (Vlaanderen), pred. Aalten 11 mei 1817, Hooge Zwaluwe 9 april 1826, Monster 4 mei 1828, Zevenbergen 5 april 1840, emer. 1855; overl. 4 aug. 1863.<130>\n",
    "    REASON: second pred. was missing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace('(Vlaanderen)§§', '(Vlaanderen)§§, pred.').replace('overl. 28 maart 1715.<1185>', ' overl. 28 maart 1715.<1185>').replace('>pred.', ' pred.').replace('Leeuwen, van, Cornelis [z.v. Cornelis]','Leeuwen, van; Cornelis [z.v. Cornelis]',).replace('Peenen, van, Marcus','Peenen, van; Marcus').replace('Knuyt, de (Kuntius), Elias','Knuyt, de (Kuntius); Elias').replace('Leonardis, de, Paulus','Leonardis, de; Paulus').replace('Lutheraan;§§onwettig','Lutheraan; onwettig')\n",
    "data = data.replace('§', '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da37b3f",
   "metadata": {},
   "source": [
    "To get alle the information of the file into single rows per individual the first step was to remove all the enters in the file so that all the information of an individual is stored in a single row. Since all the individuals have a unique ID structured as <x> where x is the id. The next step thus was to add an enter after every ID creating a file that has information of every individual in a single row.\n",
    "\n",
    "> Aalst, van; Cornelius Geb. Castricum ca. 1686; ambassadepred. in Parijs maart tot dec. 1715; pred. Kalslagen ber. 21 febr. 1717, emer. 1751; overl. Amsterdam 27 aug. 1756.<2>\n",
    "> Aalst, van; Gerardus Geb. xxx sept. 1678; pred. Vuren en Dalem 10 aug. 1704, Sommelsdijk 13 juni 1706, West Zaandam 4 aug. 1715, emer. 1755; overl. 29 juni 1759.<3>\n",
    "\n",
    "To isolate the IDs into a column once read as a .csv file a semicolon is added in front of the < and after the > sign. We decided to call the ids drc_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a65b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace semicolons with newlines and add semicolons around < and > since these identify the IDs\n",
    "data = data.replace(';', ';\\n').replace(';\\n ', '; ').replace('>', '>;\\n ').replace('<', ';<')\n",
    "lines = data.split('\\n')\n",
    "\n",
    "lines = [line for line in lines if not line.startswith('; ;') and not line.startswith('; ')]\n",
    "data = '\\n'.join(lines)\n",
    "lines = data.strip().split('\\n')\n",
    "data = '\\n'.join([line.lstrip() for line in lines])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb96ba",
   "metadata": {},
   "source": [
    "### Step 2.\n",
    "In the original dataset the various characteristics of an individual are distinguished using s semicolon. However, this is not done in a systematic way (e.g Geb. and  emer. Are not separated with a semicolon. Therefore, a search on the various **distinguishable key strings** is performed and a semicolon is added. Key strings that we searched for are:\n",
    "\n",
    "``` \"Geb.\",\"pred.\",\"overl.\",\"Gedoopt\",\"legerpred.\",\"pastoor\",\"garnizoenspred.\",\"emer.\",\"begraven\",\"conrector\",\"rector\",\"monnik\",\"schoolmeester\",\"hoogleraar\",\"chirurgijn\",\"praeceptor\",\"ziekentrooster\",\"vlootpred.\",\"legerpred.\",\"ambassadepred.\" ```\n",
    "\n",
    "and many more...\n",
    "\n",
    "By added a “; ” in front of these key strings the various will be handled as separate columns when imported as .csv file.\n",
    "\n",
    "> Aalst, van; Cornelius ; Geb. Castricum ca. 1686; ; ambassadepred. in Parijs maart tot dec. 1715; ; pred. Kalslagen ber. 21 febr. 1717, ; emer. 1751; ; overl. Amsterdam 27 aug. 1756.;<2>;\n",
    "> Aalst, van; Gerardus ; Geb. xxx sept. 1678; ; pred. Vuren en Dalem 10 aug. 1704, Sommelsdijk 13 juni 1706, West Zaandam 4 aug. 1715, ; emer. 1755; ; overl. 29 juni 1759.;<3>;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03823c0b",
   "metadata": {},
   "source": [
    "Individuals could have been minister in multiple places and also have \"gaps\" in their minister carreer. For example:\n",
    "\n",
    "> Haack; Petrus Geb. Brielle okt. 1747; pred. Noordgouwe 26 nov. 1769, Zwartewaal 20 nov. 1774, Sommelsdijk 6 juli 1777, Breda 23 juni 1782, Amsterdam 25 nov. 1789, politiek afgezet 1796; vertrokken naar Hamburg, hersteld: pred. Amsterdam 1804, overl. 27 juli 1824.<3782>\n",
    "\n",
    "The individual in this example was a minister in Noorgouwe from 1769 followed by positions in Zwartewaal from 1774, Sommelsdijk from 1777, Breda from 1782 and Amsterdam from 1789. In 1796 he was fired after which he went to Hamburg. In 1804 he was reinstalled in Amsterdam until he passed away in 1824. As can be noticed in this exmple, the various roles as minister do not all start with pred. . Subsequent positions are only seperated with a comma. Then, if someone was reinstalled as a minister this information starts with pred. again. To lateron merge all the locations of where someone was minister into one field zx and the position pred. is used in the row is added to the front of the \" pred.\" string. The reason to add zx is since this was unique in the dataset. \n",
    "\n",
    "By adding a count the values of these fields can lateron be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_pred_count(string):\n",
    "    count = 0\n",
    "    result = \"\"\n",
    "    position = string.find(\" pred.\")\n",
    "\n",
    "    while position != -1:\n",
    "        result += string[:position] + \"zx\"+ str(count) + \" pred.\"\n",
    "        string = string[position + len(\" pred.\"):]\n",
    "        count += 1\n",
    "        position = string.find(\" pred.\")\n",
    "\n",
    "    result += string\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea12c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = data.split('\\n')\n",
    "\n",
    "with open(output_txt, \"w\", encoding='utf-8') as file:\n",
    "    for line in lines:\n",
    "        result_string = replace_pred_count(line)\n",
    "        file.write(result_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac4a1a3",
   "metadata": {},
   "source": [
    "Here the various identified **distinguishable key strings** are listed. This covered most of the seperate entities, yet after the manual curation more occurred (sometimes only once or twice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f7139",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = (\"Geb.\",\n",
    " \"zx0 pred.\",\n",
    " \"zx1 pred.\",\n",
    " \"zx2 pred.\",\n",
    " \"zx3 pred.\",\n",
    " \"zx4 pred.\",\n",
    " \"overl.\",\n",
    " \"Gedoopt\",\n",
    " \"legerpred.\",\n",
    " \"pastoor\",\n",
    " \"garnizoenspred.\",\n",
    " \"emer.\",\n",
    " \"begraven\",\n",
    " \"conrector\",\n",
    " \" rector\",\n",
    " \"monnik\",\n",
    " \"schoolmeester\",\n",
    " \"hoogleraar\",\n",
    " \"chirurgijn\",\n",
    " \"praeceptor\",\n",
    " \"ziekentrooster\",\n",
    " \"vlootpred.\",\n",
    " \"legerpred.\",\n",
    " \"ambassadepred.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82350e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns:\n",
    "    with open(output_txt, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    with open(output_txt,'w', encoding='utf-8') as f:\n",
    "        for line in lines:\n",
    "            if \"; \"+column in line:\n",
    "                f.write(line)\n",
    "            elif column in line:\n",
    "                line = line.replace(column, \";\"+column)\n",
    "                f.write(line)\n",
    "            else:\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd75de7",
   "metadata": {},
   "source": [
    "The surnames and names of the individuals in the dataset are always stored in the first and second column of the dataset. Therefore the first two columns are given have been named accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7518a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the headers for the output file\n",
    "headers = ['surname_temp', 'first_name', 'Field1', 'Field2', 'Field3', 'Field4', 'Field5', 'Field6', 'Field7', 'Field8', 'Field9', 'Field10', 'Field11','Field12','Field13','Field14','Field15','Field16','Field17','Field18']\n",
    "\n",
    "with open(output_txt, 'r', encoding='utf-8') as infile, open(output_csv, 'w', newline='', encoding='utf-8' ) as outfile:\n",
    "    reader = csv.reader(infile, delimiter=';')\n",
    "    writer = csv.writer(outfile, delimiter=';')\n",
    "\n",
    "    # Write the headers to the output file\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    # Loop through each row in the input file and write it to the output file with 12 fields\n",
    "    for row in reader:\n",
    "        # Create a new row with 12 fields by extending the current row with empty values\n",
    "        new_row = row + [''] * (12 - len(row))\n",
    "        writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451cdd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_csv, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "modified_content = content.replace(\"§ \", \"-\")\n",
    "\n",
    "with open(output_csv, 'w') as file:\n",
    "    file.write(modified_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402aee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_csv, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45810564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the file all IDs, which are called \"drc_id\" are stored between < and > therefore:\n",
    "\n",
    "for column in df.columns:\n",
    "# Check if any value in the column contains '<'\n",
    "    if df[column].astype(str).str.contains('<').any():\n",
    "# Copy the values containing '<' to a column\n",
    "        df.loc[df[column].astype(str).str.contains('<'), 'drc_id'] = df[column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1670351",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['drc_id'] = df['drc_id'].str.replace('>', '').str.replace('<','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d000fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns:\n",
    "    df[column] = df.apply(lambda row: row[row.astype(str).str.contains(column)].iloc[0] if any(row.astype(str).str.contains(column)) else '', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea2900a",
   "metadata": {},
   "source": [
    "To ensure that the orginal input remains accessible for the user aftewards, which appears to be essential for the data curation process, the original input is reconstructed by the following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd89d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['original_input'] = df['surname_temp'].fillna('') + df['first_name'].fillna('') + df['Field1'].fillna('') + df['Field2'].fillna('')+ df['Field3'].fillna('')+ df['Field4'].fillna('')+ df['Field5'].fillna('')+ df['Field6'].fillna('')+ df['Field7'].fillna('')+ df['Field8'].fillna('')+ df['Field9'].fillna('')+ df['Field10'].fillna('')+ df['Field11'].fillna('')+ df['Field12'].fillna('')+ df['Field13'].fillna('')+ df['Field14'].fillna('')+ df['Field15'].fillna('')+ df['Field16'].fillna('')+ df['Field17'].fillna('')+ df['Field18'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fbda58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['original_input'] = df['original_input'].str.replace('zx0 pred. ', ' pred. ').str.replace('zx1 pred.',' pred. ').str.replace('zx2 pred.',' pred. ').str.replace('zx3 pred.',' pred. ').str.replace('zx4 pred.',' pred. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cb78bb",
   "metadata": {},
   "source": [
    "### Step 3.\n",
    "When importing this dataset, it will create a lot of empty cells and obviously does not structure the data according to the distinguishable key string. Therefor the next step is to create columns based on the key strings and add information from cells that contain the key string into that column. To improve the readability of the information in the new columns the key strings are also removed.\n",
    "\n",
    "In the example information about Cornelius´s death will be stored into column **overl.** and will initially contain the value *“ overl. 29 juni 1759.”*, however once the distinguishable string is removed from the cell it will contain as value *“29 juni 1759.”*.\n",
    "\n",
    "An important issue here is that in some cases the distinguishable key string is used multiple times for an individual. For ministers this issue has been solved by counting the number of time the string “ pred.” is in a line and add a number to the position. These are later on integrated into one cell called minister."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1813a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns:\n",
    "    df[column] = df[column].str.replace(column, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c912c",
   "metadata": {},
   "source": [
    "### Step 4. \n",
    "The fields **first_name** and **surname**  also contain alternative surnames and information about family relations.\n",
    "\n",
    "In the original text files all information about alternative surnames is provided between ( ) and about family relationships between [ ]. As a next step we thus have cutted information between ( ) in the field **surname_name** into a new field called **name_info_family** and from **surname** information between [ ] into a new field called **alternative_name**. Once the additional information is moved from **first_name** and **surname** columns, the infixes of the various individuals can be isolated by searching for a comma in the column **surname**.\n",
    "\n",
    "\n",
    "Since information about the family, like the son of, is always put [ ] as part of the first name this information is isolated into **name_info_family**. \n",
    "\n",
    "e.g. \n",
    "\n",
    "> Abbinck; Lambertus Hermanus [broer van Tieleman] Geb. Zutphen 4 juli 1771; pred. Bahr, Lathum en Giesbeek 19 okt. 1794, Groenlo 13 april 1806, overl. 20 nov. 1838.<26>\n",
    "> Hartman; Rudolph [z.v. Constantinus] Geb. Enkhuizen 2 aug. 1668; vlootpred. 1689; pred. Steenbergen (NBr) + Kruisland 3 sept. 1690, overl. 26 juli 1700.<4022>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c43e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['name_info_family'] =df['first_name'] .str.extract(r'\\[(.*?)\\]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921f6a1",
   "metadata": {},
   "source": [
    "Altenative surnames are always put between ( ) and are isolated into a field alternative_name.\n",
    "\n",
    "e.g. \n",
    "> Haitsema; Messias (Mesche) Loban Gedoopt Winschoten 19 febr. 1673; pred. Weener (Oost-Friesland) 1695, Winschoten 17 april 1698, overl. 30 juli 1698.<3857>\n",
    "> Gruterus (de Gruyter); Samuel Simonsz. Geb. Leiden yyy; pred. Delfshaven 1605, overl. 1634.<3750>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d320495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alternative_name'] =df['surname_temp'] .str.extract(r'\\((.*?)\\)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9030e622",
   "metadata": {},
   "source": [
    "Remove all the alternative surnames and information about the family out of the field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e324aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['surname_temp']= df['surname_temp'].str.replace(r'\\(.*\\)', '', regex=True)\n",
    "df['first_name']= df['first_name'].str.replace(r'\\[.*\\]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['surname', 'infix']] = df['surname_temp'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e6394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_letter'] = df['first_name'].astype(str).apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['surname_temp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01e2248",
   "metadata": {},
   "source": [
    "\n",
    "### Step 5.\n",
    "In order to make the various field into understandable entities, the names of the columns have been translated to English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_rename = {\n",
    "    'Geb.': 'birth',\n",
    "    'overl.': 'death',\n",
    "    'Gedoopt':'baptized',\n",
    "    'legerpred.':'legerpredikant',\n",
    "    'pastoor':'pastoor',\n",
    "    'garnizoenspred.':'garnizoenspredikant',\n",
    "    \"emer.\":'emeritus_status',\n",
    "    \"begraven\":'burried',\n",
    "    \"conrector\":'conrector',\n",
    "    \" rector\":'rector',\n",
    "    \"monnik\":'monnik',\n",
    "    \"schoolmeester\":'schoolmeester',\n",
    "    \"hoogleraar\":'hoogleraar',\n",
    "    \"chirurgijn\":'chirurgijn',\n",
    "    \"praeceptor\":'praeceptor',\n",
    "    \"ziekentrooster\":'ziekentrooster',\n",
    "    \"vlootpred.\":'vlootpredikant',\n",
    "    \"legerpred.\":'legerpredikant',\n",
    "    \"ambassadepred.\":'ambassadepredikant'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ad5aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "df = df.rename(columns=columns_rename)\n",
    "new_columns = list(columns_rename.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c036cae",
   "metadata": {},
   "source": [
    "Now that all the information from the fields have been parsed to the right column, we can drop the unassigned fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4164a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_drop = [i for i in range(1, 19)]\n",
    "for dropid in array_drop:\n",
    "    column_dropid = 'Field'+str(dropid)\n",
    "    df = df.drop(column_dropid, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4721e9",
   "metadata": {},
   "source": [
    "### Step 6. \n",
    "Here all the fields that contain information about an individual's role as minister are merged. This field will produce a string with all the locations and years someone was minister in sesequent order.\n",
    "\n",
    "For example:\n",
    "\n",
    ">Haack; Petrus Geb. Brielle okt. 1747; pred. Noordgouwe 26 nov. 1769, Zwartewaal 20 nov. 1774, Sommelsdijk 6 juli 1777, Breda 23 juni 1782, Amsterdam 25 nov. 1789, politiek afgezet 1796; vertrokken naar Hamburg, hersteld: pred. Amsterdam 1804, overl. 27 juli 1824.<3782>\n",
    "\n",
    "Became \n",
    "\n",
    "| drc_id  | ... | ... | zx0 pred. | zx1 pred. | zx2 pred. | zx3 pred. | zx4 pred. | ... | etc. |\n",
    "|---|---|---|---|---|---|---|---|---|---|\n",
    "| 2 |\t |\t\t| Noordgouwe 26 nov. 1769, Zwartewaal 20 nov. 1774, Sommelsdijk 6 juli 1777, Breda 23 juni 1782, Amsterdam 25 nov. 1789\t| Amsterdam 1804\t|  \t| | | | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['minister'] = df['zx0 pred.']+ ','+df['zx1 pred.']+ ','+df['zx2 pred.']+ ','+df['zx3 pred.']+ ','+df['zx4 pred.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da024692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['zx0 pred.','zx1 pred.','zx2 pred.','zx3 pred.','zx4 pred.'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379bfc55",
   "metadata": {},
   "source": [
    "And is now converted into\n",
    "\n",
    "| drc_id  | ... | ... | minister | ... | etc. |\n",
    "|---|---|---|---|---|---|\n",
    "| 2 |\t |\t\t| Noordgouwe 26 nov. 1769, Zwartewaal 20 nov. 1774, Sommelsdijk 6 juli 1777, Breda 23 juni 1782, Amsterdam 25 nov. 1789, Amsterdam 1804\t|  \t| |\n",
    "\n",
    "Where the commas sperate the various locations and starting moment where someone was minister.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9fbaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(text):\n",
    "    match = re.search(r'\\d{4}', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d6874",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_year = [word for word in new_columns if word != 'minister']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in function_year:\n",
    "    fld_year = year +'_year'\n",
    "    df[fld_year] = df[year].apply(lambda x: extract_year(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae689d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year_accu in function_year:\n",
    "    accu_fld_year = year_accu +'_year_accuracy'\n",
    "    df[accu_fld_year] = ''\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Check if the string contains \"ca.\" (case-insensitive)\n",
    "        if 'ca.' in row[year_accu].lower():\n",
    "            # If found, set the value of the \"accuracy\" column to \"circa\"\n",
    "            df.at[index, accu_fld_year] = 'circa'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba0e15",
   "metadata": {},
   "source": [
    "To keep the information about specific dates the information isolated from the fields are added a a remark field. This allows to lateron write queries that allow to extract specific information about dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea4ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for remark in function_year:\n",
    "    remarks_field = 'remarks_'+remark\n",
    "    df[remarks_field] = df[remark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "months =(\" januari \",\n",
    " \" februari \",\n",
    " \" maart \",\n",
    " \" april \",\n",
    " \" mei \",\n",
    " \" juni \",\n",
    " \" juli \",\n",
    " \" augustus \",\n",
    " \" september \",\n",
    " \" oktober \",\n",
    " \" november \",\n",
    " \" december \",\n",
    " \"jan. \",\n",
    " \"feb. \",\n",
    " \"mrt. \",\n",
    " \"apr. \",\n",
    " \"jun. \",\n",
    " \"jul. \",\n",
    " \"aug. \",\n",
    " \"sept. \",\n",
    " \"sep. \",\n",
    " \"okt. \",\n",
    " \"nov. \",\n",
    " \"dec. \",\n",
    " \"yyy\",\n",
    " \"xxx\",\n",
    " \"ca.\",\n",
    " \"febr.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672e997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_strip in function_year:\n",
    "    for month in months:\n",
    "        df[column_strip] = df[column_strip].str.replace(month, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b5c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_strip in function_year:\n",
    "    df[column_strip] = df[column_strip].apply(lambda x: re.sub(r'[\\d\\.]', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3e4f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to link the DRC with DM a join field is created based on the surname, firstname and the infix.\n",
    "\n",
    "df['join_name'] = df['surname']+df['first_name']+df['infix'].fillna('')\n",
    "df['join_name'] = df['join_name'].str.replace(\"  \",\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13891858",
   "metadata": {},
   "source": [
    "### Step 8. \n",
    "\n",
    "Since an individual might have had multiple positions as minister, the relation between an individual and a role is considered one-to-many. The process above added all the information of a minister career into one field, where every new location and year is distinguished by a , . The next step has therefore been to isolate the information from the column “minister” into a new table where every role has a separate row contain the unique ID and the information about the role. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a74639",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_elements = ['birth', 'death', 'baptized', 'burried']\n",
    "\n",
    "roles = [item for item in function_year if item not in exclude_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2051c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_role_dfs = []\n",
    "\n",
    "for role in roles:\n",
    "    accu_year = role +'_year_accuracy'\n",
    "    year = role + '_year'\n",
    "    role_remarks = 'remarks_'+role\n",
    "    role_df = role\n",
    "    role_df = df[['drc_id',role,year,accu_year,role_remarks]]\n",
    "    columns_to_check = [role, year, accu_year, role_remarks]\n",
    "    role_df = role_df[role_df[columns_to_check].notna().all(axis=1)]\n",
    "    new_column_names = {role:'role_place', accu_year : 'role_start_year_accuracy', year : 'role_start_year', role_remarks : 'role_remarks'}\n",
    "    role_df.rename(columns=new_column_names, inplace=True)\n",
    "    role_df['role_type'] = role\n",
    "    child_role_dfs.append(role_df)\n",
    "\n",
    "child_role = pd.concat(child_role_dfs, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e274d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['place_birth'] = df['birth']\n",
    "df['place_death'] = df['death']\n",
    "df['place_baptized'] = df['baptized']\n",
    "df['place_burried'] = df['burried']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca2bf4d",
   "metadata": {},
   "source": [
    "The information about the parent is parsed to a seperate table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eddace",
   "metadata": {},
   "outputs": [],
   "source": [
    "drc_parent = df[['drc_id','first_name', 'infix', 'surname', 'first_letter', 'place_birth', 'place_death', 'place_baptized', 'place_burried', 'name_info_family',  'birth_year', 'death_year', 'baptized_year', 'burried_year', 'birth_year_accuracy', 'death_year_accuracy', 'baptized_year_accuracy', 'burried_year_accuracy']]\n",
    "drc_parent.to_csv(folderlink+folder_output+'01_bio_drc.csv', sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424c7c9",
   "metadata": {},
   "source": [
    "Alternative names are stored as a seperate table, since in theory individuals have multiple alternative names. Yet since non have been found we decided to leave this seperation for the manual curation phase.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bfbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drc_child_alt_name = df[['drc_id','alternative_name']]\n",
    "drc_child_alt_name.to_csv(folderlink+folder_output+'11_alt_name_drc.csv', sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77f94d7b",
   "metadata": {},
   "source": [
    "### Step 9. \n",
    "Now we create the child relation for roles. For this we first seperated ministers after which the other roles were added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59da6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_pred = df[['drc_id', 'minister','first_letter','join_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f4bd48",
   "metadata": {},
   "source": [
    "Here the information about the role minister, that is created above in step 6 is split to different rows.\n",
    "\n",
    "from: \n",
    "\n",
    "| clerus_id  | ... | ... | minister | ... | etc. |\n",
    "|---|---|---|---|---|---|\n",
    "| 2 |\t |\t\t| Noordgouwe 26 nov. 1769, Zwartewaal 20 nov. 1774, Sommelsdijk 6 juli 1777, Breda 23 juni 1782, Amsterdam 25 nov. 1789, Amsterdam 1804\t|  \t| |\n",
    "\n",
    "\n",
    "to:\n",
    "\n",
    "| clerus_id  | minister | ... | etc. |\n",
    "|---|---|---|---|\n",
    "| 2 | Noordgouwe 26 nov. 1769|  \t| |\n",
    "| 2 | Zwartewaal 20 nov. 1774|  \t| |\n",
    "| 2 | Sommelsdijk 6 juli 1777|  \t| |\n",
    "| 2 | Breda 23 juni 1782, Amsterdam 25 nov. 1789, Amsterdam 1804\t|  \t| |\n",
    "| 2 | Amsterdam 25 nov. 1789|  \t| |\n",
    "| 2 | Amsterdam 1804\t|  \t| |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded = subset_pred.assign(minister=subset_pred['minister'].str.split(','))\n",
    "\n",
    "# Explode the 'pred.' column to create separate rows for each item\n",
    "df_expanded = df_expanded.explode('minister')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_expanded[['drc_id','first_letter', 'minister','join_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdef549",
   "metadata": {},
   "source": [
    "It produced some empty rows that need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "childs = df_filtered[(df_filtered[\"minister\"] !=\" \") & (df_filtered[\"minister\"] !=\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "childs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a9cb91",
   "metadata": {},
   "source": [
    "The procedure is repeated isolate the year into a different field, add circa and keep the original input as remarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6842d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "childs['minister_year'] = childs['minister'].apply(lambda x: extract_year(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a766bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "childs['role_start_year_accuracy'] = ''\n",
    "childs.loc[childs['minister'].str.contains('ca\\.', case=False), 'role_start_year_accuracy'] = 'circa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95d8ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "childs['role_remarks'] = childs['minister']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a17750",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in months:\n",
    "        childs['minister'] = childs['minister'].str.replace(month, '')\n",
    "\n",
    "childs['minister'] = childs['minister'].apply(lambda x: re.sub(r'[\\d\\.]', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad39199e",
   "metadata": {},
   "source": [
    "A new field is created with the role type. For this \"predikant\" is filled in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "childs['role_type'] = \"predikant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c53ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names_min = {'minister':'role_place', 'minister_year' : 'role_start_year'}\n",
    "childs.rename(columns=new_column_names_min, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23553646",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_minister = childs[['drc_id', 'role_type','role_place','role_start_year','role_start_year_accuracy','role_remarks']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d950e7a7",
   "metadata": {},
   "source": [
    "### Step 10. \n",
    "Next the other roles are integrated into every row and added in a child_roles.csv output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7309a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_roles = pd.concat([child_role, role_minister], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_roles.to_csv(folderlink+folder_output+'12_roles_drc.csv', sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73546c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_roles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(output_txt)\n",
    "os.remove(output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9cf1e",
   "metadata": {},
   "source": [
    "# Final remarks.\n",
    "\n",
    "As said, this workflow provided the steps that were taken to process the DRC file form a word document to a series of csv which can be integrated into a Relational Database Management System. The dataprocessing converted 7111 out of the 12579 individuals successfully. For 5468 individuals modiffications were made based on the data curation. The notebook above thus helped in structuring the dataset and isolate various fields. Yet, since there were many exceptions a manual curation was essential. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digidure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
