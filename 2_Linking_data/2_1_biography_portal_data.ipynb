{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting dataset from Biography portal of the Netherlands CLERUS\n",
    "\n",
    "## Description of Dutch Biography Portal data\n",
    "\n",
    "In order to connect inidividuals from the [Dutch Biography Portal](http://www.biografischportaal.nl/en/) we have been provided with an excel sheet from the datacurator of this portal. The dataset we have been provided with contains the following fields.\n",
    "\n",
    "|Fieldname | Description|\n",
    "|----|---|\n",
    "|Badge| internal badge id|\n",
    "|Bioport_id| unique id in bioportal to link it to other datasources |\n",
    "|Person_id|unique id of individual|\n",
    "|prepositie| preposition, an official title like duke or dr.|\n",
    "|voornaam| first name|\n",
    "|intrapositie| infix |\n",
    "|pnv_infixTitle| infix title |\n",
    "|geslachtsnaam| surname |\n",
    "|postpositie| postposition |\n",
    "|person_sex| gender |\n",
    "|VIAF_id_1| Virtual International Authority File Id to link with other datasources |\n",
    "|VIAF_id_2| Virtual International Authority File Id to link with other datasources when a second is known |\n",
    "|Wikidata_id| Id to wikidata |\n",
    "|event_birth_when| Birth date |\n",
    "|event_birth_text| additional information about the birth, mostly date of baptism | \n",
    "|event_birth_place| place of birth or baptism |\n",
    "|event_death_when| date of death |\n",
    "|event_death_text| additional information about the death, e.g. date of funeral |\n",
    "|event_death_place| place of death or burial | \n",
    "|category-1| category for which the inidivual was known for |\n",
    "|category-2| second category for which the inidivual was known for |\n",
    "|category-3| additional category for which the inidivual was known for |\n",
    "|category-4| additional category for which the inidivual was known for |\n",
    "|religion| information about the relgion of an individual |\n",
    "\n",
    "*Table 1 - fields Dutch Biography portal*\n",
    "\n",
    "To link individuals from CLERUS dataset with data from the Biography Portal (BP) a string is created combining the first letter of the name, the infix, the surname and the year of birth in both datasets. \n",
    "\n",
    "From CLERUS this string match is created through the table **01_clerus_bio** for the fields **first_name**, **infix**, **surname** , **birth_year**. From BP these are derived from the first letter of **voornaam**, **intrapositie**, **geslachtsnaam**, **event_birth_when**. For **event_birth_when** the first 4 digital number has been isolated assuming that is the year of birth.\n",
    "\n",
    "For field where these corresponded we have created a list containing the Bioport_id and clerus_id. This outcome of this script is meant to enrich BP and CLERUS. In total this resulted in 1199 matches between the biography portal and the CLERUS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for the the datasets (i.e. the input location of the file to be processed and the output location) )\n",
    "\n",
    "folderlink = '..//data//'\n",
    "folder_input = 'input//bioportal//'\n",
    "input_file_bio = os.path.join(folderlink+folder_input, '2019_12_10_BioPort_BPR_MASTERFILE.csv')\n",
    "folder_output = 'output//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_access_to_dataframes(database_path):\n",
    "    # Connection string for Access database\n",
    "    conn_str = (\n",
    "        r'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};'\n",
    "        r'DBQ=' + database_path + ';'\n",
    "    )\n",
    "\n",
    "    # Establish a connection to the Access database\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get a list of all tables in the database\n",
    "    tables = [row.table_name for row in cursor.tables(tableType='TABLE')]\n",
    "\n",
    "    # Loop through the tables and load each into a DataFrame\n",
    "    for table in tables:\n",
    "        query = f'SELECT * FROM [{table}]'\n",
    "        df = pd.read_sql(query, conn)\n",
    "        globals()[f'tbl_{table}'] = df  # Create a global variable with the table name\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maurice de Kleijn\\AppData\\Local\\Temp\\ipykernel_18500\\1595437475.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Maurice de Kleijn\\AppData\\Local\\Temp\\ipykernel_18500\\1595437475.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Maurice de Kleijn\\AppData\\Local\\Temp\\ipykernel_18500\\1595437475.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Maurice de Kleijn\\AppData\\Local\\Temp\\ipykernel_18500\\1595437475.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Maurice de Kleijn\\AppData\\Local\\Temp\\ipykernel_18500\\1595437475.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Maurice de Kleijn\\AppData\\Local\\Temp\\ipykernel_18500\\1595437475.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Maurice de Kleijn\\AppData\\Local\\Temp\\ipykernel_18500\\1595437475.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\Maurice de Kleijn\\AppData\\Local\\Temp\\ipykernel_18500\\1595437475.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Link with CLERUS database (which is the result of the data Harmonization steps)\n",
    "clerus_database_path = 'E:\\\\digidure\\\\CLERUS_v3_06082024.accdb'\n",
    "export_access_to_dataframes(clerus_database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panda settings for showing data\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maurice de Kleijn\\AppData\\Local\\Temp\\ipykernel_18500\\53350405.py:1: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  bio = pd.read_csv(input_file_bio, sep=';', encoding='utf-8')\n"
     ]
    }
   ],
   "source": [
    "# Load the biography portal datadump, parse the various field and create a string to match CLERUS with\n",
    "bio = pd.read_csv(input_file_bio, sep=';', encoding='utf-8')\n",
    "bio['birth_year'] = bio['event_birth_when'].str.extract(r'(\\d{4})')\n",
    "bio['first_letter'] = bio['voornaam'].astype(str).apply(lambda x: x[0])\n",
    "bio['bio_name_surname_year'] = (bio['first_letter'].astype(str) + '_' + np.where(bio['intrapositie'].isna(), '', bio['intrapositie'].astype(str)) + '_' + bio['geslachtsnaam'].astype(str) + '_' + np.where(bio['birth_year'].isna(), '', bio['birth_year'].astype(str)))\n",
    "bio = bio[~bio['birth_year'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access Clerus Bio dataframe and create a string to matcht the biography portal data with\n",
    "tbl_01_clerus_bio['first_letter'] = tbl_01_clerus_bio['first_name'].astype(str).apply(lambda x: x[0] if len(x) > 1 else None)\n",
    "tbl_01_clerus_bio = tbl_01_clerus_bio[~tbl_01_clerus_bio['birth_year'].isna()]\n",
    "tbl_01_clerus_bio['birth_year'] = tbl_01_clerus_bio['birth_year'].astype(str)\n",
    "tbl_01_clerus_bio['birth_year']= tbl_01_clerus_bio['birth_year'].str.extract(r'(\\d{4})')\n",
    "tbl_01_clerus_bio['clerus_name_surname_year'] = (tbl_01_clerus_bio['first_letter'].astype(str) + '_' + np.where(tbl_01_clerus_bio['infix'].isna(), '', tbl_01_clerus_bio['infix'].astype(str)) + '_' + tbl_01_clerus_bio['surname'].astype(str) + '_' + tbl_01_clerus_bio['birth_year'].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link Clerus and BP\n",
    "clerus_bio = pd.merge(tbl_01_clerus_bio, bio, left_on='clerus_name_surname_year', right_on='bio_name_surname_year', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the file as csv\n",
    "clerus_bio.to_csv(folderlink+folder_output+'clerus_bp.csv', sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subset with only the id fields (ideally these would be added to both datasets)\n",
    "clerus_bio_id_links = clerus_bio[['clerus_id','Person_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clerus_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1221.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6353.720721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4876.574665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2962.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5484.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8681.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30014.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          clerus_id\n",
       "count   1221.000000\n",
       "mean    6353.720721\n",
       "std     4876.574665\n",
       "min        6.000000\n",
       "25%     2962.000000\n",
       "50%     5484.000000\n",
       "75%     8681.000000\n",
       "max    30014.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clerus_bio_id_links.describe() # 1221 links with biography portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the file as csv\n",
    "clerus_bio_id_links.to_csv(folderlink+folder_output+'clerus_bp_id_links.csv', sep=';', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
