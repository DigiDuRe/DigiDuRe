{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the various libraries\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "current_date = datetime.now()\n",
    "formatted_date = current_date.strftime('%d%m%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for files\n",
    "folderlink = '..//data//'\n",
    "input_folder = 'input//'\n",
    "folder_output = 'output//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sparql endpoint\n",
    "sparql_endpoint = \"http://data.bibliotheken.nl/sparql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kb = \"nbt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sparql_and_convert_to_df(sparql_endpoint, query):\n",
    "    sparql = SPARQLWrapper(sparql_endpoint)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    bindings = results[\"results\"][\"bindings\"]\n",
    "    data = []\n",
    "    for item in bindings:\n",
    "        row = {}\n",
    "        for key in item:\n",
    "            row[key] = item[key][\"value\"]\n",
    "        data.append(row)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key = pd.DataFrame()\n",
    "\n",
    "for value_int in range(0, 30000000, 10000000):\n",
    "    value_str = str(value_int)\n",
    "    query = \"\"\"\n",
    "    SELECT ?title_id ?title WHERE {\n",
    "    ?title_id schema:name ?title .\n",
    "    ?title_id schema:mainEntityOfPage/schema:isPartOf <http://data.bibliotheken.nl/id/dataset/\"\"\"+dataset_kb+\"\"\"> .\n",
    "    }\n",
    "    LIMIT 10000000 OFFSET \"\"\"+value_str+\"\"\"\n",
    "    \"\"\"\n",
    "    df = query_sparql_and_convert_to_df(sparql_endpoint, query)\n",
    "    primary_key = pd.concat([primary_key, df], ignore_index=True)\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the dataset of the KB multiple spellings of names have been added. And accessible through:\n",
    "# ?title_id schema:author/schema:name ?author .\n",
    "# ?title_id schema:author/schema:birthDate ?birthdate .\n",
    "# Ideally we would want multiple spellings, however due to limited server response from the KB it has been decided to keep it with the label (which contains the year of birth as well) and lateron extract them.\n",
    "# For future analysis it is recommended to optimize this.\n",
    "\n",
    "author = pd.DataFrame()\n",
    "\n",
    "\n",
    "for value_int in range(0, 50000000, 10000000):\n",
    "    value_str = str(value_int)\n",
    "    query = \"\"\"\n",
    "    SELECT ?title_id ?author WHERE {\n",
    "        ?title_id schema:author/rdfs:label ?author .\n",
    "        ?title_id a schema:Book .\n",
    "        ?title_id schema:name ?title .\n",
    "        ?title_id schema:mainEntityOfPage/schema:isPartOf <http://data.bibliotheken.nl/id/dataset/\"\"\"+dataset_kb+\"\"\"> .\n",
    "    }\n",
    "    LIMIT 10000000 OFFSET \"\"\"+value_str+\"\"\"\n",
    "    \"\"\"\n",
    "    df = query_sparql_and_convert_to_df(sparql_endpoint, query)\n",
    "    author = pd.concat([author, df], ignore_index=True)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_author = pd.DataFrame()\n",
    "\n",
    "for value_int in range(0, 50000000, 10000000):\n",
    "    value_str = str(value_int)\n",
    "    query = \"\"\"\n",
    "    select ?title_id ?co_author where {\n",
    "        ?title_id schema:contributor/rdfs:label ?co_author.\n",
    "        ?title_id a schema:Book .\n",
    "        ?title_id schema:name ?title .\n",
    "        ?title_id schema:mainEntityOfPage/schema:isPartOf <http://data.bibliotheken.nl/id/dataset/\"\"\"+dataset_kb+\"\"\"> .\n",
    "    }\n",
    "    LIMIT 10000000 OFFSET \"\"\"+value_str+\"\"\"\n",
    "    \"\"\"\n",
    "    df = query_sparql_and_convert_to_df(sparql_endpoint, query)\n",
    "    co_author = pd.concat([co_author, df], ignore_index=True)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_year = pd.DataFrame()\n",
    "\n",
    "for value_int in range(0, 30000000, 10000000):\n",
    "    value_str = str(value_int)\n",
    "    query = \"\"\"\n",
    "    select ?title_id ?pub_year where {\n",
    "    ?title_id schema:publication/schema:startDate ?pub_year .\n",
    "    ?title_id a schema:Book .\n",
    "    ?title_id schema:name ?title .\n",
    "    ?title_id schema:mainEntityOfPage/schema:isPartOf <http://data.bibliotheken.nl/id/dataset/\"\"\"+dataset_kb+\"\"\"> .\n",
    "    }\n",
    "    LIMIT 10000000 OFFSET \"\"\"+value_str+\"\"\"\n",
    "    \"\"\"\n",
    "    df = query_sparql_and_convert_to_df(sparql_endpoint, query)\n",
    "    pub_year = pd.concat([pub_year, df], ignore_index=True)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_location = pd.DataFrame()\n",
    "\n",
    "for value_int in range(0, 30000000, 10000000):\n",
    "    value_str = str(value_int)\n",
    "    query = \"\"\"\n",
    "    select ?title_id ?pub_location {\n",
    "    ?title_id schema:publication/schema:location/schema:name ?pub_location .\n",
    "    ?title_id a schema:Book .\n",
    "    ?title_id schema:name ?title .\n",
    "    ?title_id schema:mainEntityOfPage/schema:isPartOf <http://data.bibliotheken.nl/id/dataset/\"\"\"+dataset_kb+\"\"\"> .\n",
    "    }\n",
    "    LIMIT 10000000 OFFSET \"\"\"+value_str+\"\"\"\n",
    "    \"\"\"\n",
    "    df = query_sparql_and_convert_to_df(sparql_endpoint, query)\n",
    "    pub_location = pd.concat([pub_location, df], ignore_index=True)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_name = pd.DataFrame()\n",
    "\n",
    "for value_int in range(0, 30000000, 10000000):\n",
    "    value_str = str(value_int)\n",
    "    query = \"\"\"\n",
    "    select ?title_id ?publisher_name where {\n",
    "    ?title_id schema:publication/schema:organizer/schema:name ?publisher_name .\n",
    "    ?title_id a schema:Book .\n",
    "    ?title_id schema:name ?title .\n",
    "    ?title_id schema:mainEntityOfPage/schema:isPartOf <http://data.bibliotheken.nl/id/dataset/\"\"\"+dataset_kb+\"\"\"> .\n",
    "    }\n",
    "    LIMIT 10000000 OFFSET \"\"\"+value_str+\"\"\"\n",
    "    \"\"\"\n",
    "    df = query_sparql_and_convert_to_df(sparql_endpoint, query)\n",
    "    pub_name = pd.concat([pub_name, df], ignore_index=True)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = pd.merge(primary_key, pub_year, left_on='title_id', right_on='title_id', how='left')\n",
    "df_join2 = pd.merge(df_join, pub_location, left_on='title_id', right_on='title_id', how='left')\n",
    "df_join_total = pd.merge(df_join2, pub_name, left_on='title_id', right_on='title_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv and automatically fill in the date of the export\n",
    "df_join_total.to_csv(folderlink+folder_output+dataset_kb+\"_books_\"+formatted_date+\".csv\", sep=';', encoding='utf-8', index=False)\n",
    "author.to_csv(folderlink+folder_output+dataset_kb+\"_books_authors_\"+formatted_date+\".csv\", sep=';', encoding='utf-8', index=False)\n",
    "co_author.to_csv(folderlink+folder_output+dataset_kb+\"_books_co_authors_\"+formatted_date+\".csv\", sep=';', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
